---
date: 2026-01-21
tags:
  - jepa
  - associative-memory
  - prediction
  - causality
  - learning
---

# Ideas — 2026-01-21

## Associative Memory via Dual JEPA Architecture

**Core concept:** Use [[Dual JEPA Architecture|JEPA-style architecture]] for both external world modeling and internal memory association. "As within, so without" — internal experience of memory is similar to experience of the 3D world, so the same architecture can model both.

**Key insight:** The [[Inward JEPA]] isn't storing memories or rearranging them — no different to the [[Outward JEPA]] not manipulating the real world. It's learning the relationships and semantics that dictate what memories are *to each other* and *to the present*.

**Key components:**
- **Outward JEPA**: Learns object/context associations from perception (already being built)
- **Inward JEPA**: Learns memory-to-memory structure, using object associations as bridges
- **[[Long-Term Memory]] stays stable**: Embeddings represent objects/experiences, don't drift based on association
- **Associative map is the predictor network**: Learns "from this point in perception-space, these points in memory-space are reachable"
- **[[Always-On Priming]]**: Current perception continuously queries the map, keeps a relevance-weighted "warm set" over LTM
- **Task-driven retrieval**: Only surfaces to behavior/speech when context demands it
- **Long decay**: Primed items fade slowly, allowing connections across minutes and weeks

**Training signal:** Outward JEPA's learned object associations bridge memories that share objects/contexts. No separate training signal needed — world-knowledge trains memory structure automatically.

**Time as dimension, not axis:** Memories on disk aren't ordered temporally — time is just another learned feature like position or color. The associative map doesn't need special temporal machinery; it learns that action → consequence patterns have characteristic time-gaps the same way it learns objects have characteristic sizes.

**Objects as causal bridges:** Action-consequence links emerge from the pattern of "action-involving-X followed by outcome-involving-X" appearing repeatedly. Objects present in both memories create the association; causation emerges from pattern.

**Narrative override for accelerated learning:** User can explicitly link memories: "Remember when we plugged that unprotected wire in? Well, now it shorted out." This boosts an association that already exists (via shared object) but would otherwise require many repetitions to strengthen. Injects compressed human causal knowledge — shortcuts learning the way a parent shortcuts a child's experience.

### Extension: Dual Imagination-Training Loops

**Forward imagination (prediction):**
- Predict → wait → observe → loss = prediction vs reality

**Backward attribution (explanation):**
- Observe surprising outcome → hypothesize cause → vocalize → get feedback → loss = hypothesis vs explanation

Both strengthen the same predictive model. Backward attribution runs the causal chain in reverse — from outcome back to cause.

**Vocalization is key:** Forcing commitment to a specific hypothesis *before* getting the answer makes the learning signal stronger. Same mechanism documented in human learning — students who commit to an answer before seeing the solution learn faster than passive observers.

**Interaction pattern:**
- High prediction error triggers curiosity
- System searches recent memories for plausible causal links
- Surfaces best hypothesis: "I can't quite figure that out... Would this be explained by [the unprotected wire from Tuesday]?"
- User response becomes training signal:
  - "Yes, exactly" → strong weight boost
  - "No, it's because..." → new link formed, hypothesis gets slight negative weight
  - "Sort of, but..." → partial credit, nuanced update

**Developmental arc:**
- Early: "Something unexpected happened. I don't have a guess."
- Middle: "Would this be explained by X?" (often wrong, but trying)
- Mature: Handles most attribution internally, only surfaces genuinely ambiguous cases

**Transparency bonus:** Vocalized hypotheses give you a window into the model's causal understanding for free.

---

## Time as Dimension, Not Axis

Memories on disk aren't ordered temporally — time is just another learned feature like position or color. The [[Associative Memory|associative map]] doesn't need special temporal machinery; it learns that action → consequence patterns have characteristic time-gaps the same way it learns objects have characteristic sizes.

---

## Objects as Causal Bridges

Action-consequence links emerge from the pattern of "action-involving-X followed by outcome-involving-X" appearing repeatedly. Objects present in both memories create the association; causation emerges from pattern.

---

## Narrative Override for Accelerated Learning

User can explicitly link memories: "Remember when we plugged that unprotected wire in? Well, now it shorted out." This boosts an association that already exists (via shared object) but would otherwise require many repetitions to strengthen. Injects compressed human causal knowledge — shortcuts learning the way a parent shortcuts a child's experience.

---

## Dual Imagination-Training Loops

**Forward imagination (prediction):**
- Predict → wait → observe → loss = prediction vs reality

**Backward attribution (explanation):**
- Observe surprising outcome → hypothesize cause → vocalize → get feedback → loss = hypothesis vs explanation

Both strengthen the same predictive model. Backward attribution runs the causal chain in reverse — from outcome back to cause.

> See [[Prediction as Learning|docs/prediction-as-learning.md]] for more

---

## Vocalization Forces Commitment

Forcing commitment to a specific hypothesis *before* getting the answer makes the learning signal stronger. Same mechanism documented in human learning — students who commit to an answer before seeing the solution learn faster than passive observers.
